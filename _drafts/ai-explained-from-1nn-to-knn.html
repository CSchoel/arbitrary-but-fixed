<!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>Recap</title>
        <style>
</style>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
<link href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css" rel="stylesheet" type="text/css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/highlight.css">
<style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', 'HelveticaNeue-Light', 'Ubuntu', 'Droid Sans', sans-serif, 'Noto Emoji';
                font-size: 14px;
                line-height: 1.6;
            }
        </style>
        <style>
.task-list-item { list-style-type: none; } .task-list-item-checkbox { margin-left: -20px; vertical-align: middle; }
</style>
        
        <script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script>
        
    </head>
    <body class="vscode-body vscode-light">
        <hr>
<p>layout: post
title: 'AI for laypersons: From one to k nearest neighbors'
description: &gt;
In the first post of the 'AI for laypersons' series, I introduced a very simple AI based on the nearest neighbor algorithm.
In this post, I want to elaborate on this first example to arrive at a fully-fledged algorithm that is actually used for solving AI problems in the real world.
math: true
categories:</p>
<ul>
<li>artificial intelligence</li>
<li>machine learning
pdf: true</li>
</ul>
<hr>
<h2 id="recap">Recap</h2>
<p>In the [last post]({% post_url 2021-05-30-ai-explained-with-k-nearest-neighbors %}) we constructed our very first AI algorithm that was able to mimic the human decision whether a newly received email is unwanted &quot;spam&quot; or benign &quot;ham&quot;.
We also established that the technical term &quot;algorithm&quot; actually only means a step-by-step description of how to translate input values into output values.
For our spam detection algorithm this looked as follows:</p>
<h3 id="algorithm-simple-spam-detector">Algorithm: Simple spam detector</h3>
<p>Inputs:</p>
<ul>
<li><code>Database</code>: list of labeled emails</li>
<li><code>Query</code>: unlabeled email that should be classified</li>
</ul>
<p>Output:</p>
<ul>
<li><code>Label</code>: the most fitting label for the query (either &quot;spam&quot; or &quot;ham&quot;)</li>
</ul>
<p>Steps:</p>
<ol>
<li>For all labeled emails in the database, calculate the number of matching words between that email and the query.</li>
<li>Find the database entry with the maximum number of matching words.</li>
<li>Output the label attached to this database entry.</li>
</ol>
<h2 id="getting-more-generic">Getting more generic</h2>
<p>As already hinted at in the previous post, we can transform this description into a general purpose AI algorithm by replacing the term &quot;maximum number of matching words&quot; with &quot;minimum distance&quot;:</p>
<h3 id="algorithm-nearest-neighbor-classifier">Algorithm: Nearest neighbor classifier</h3>
<p>Inputs:</p>
<ul>
<li><code>Database</code>: list of labeled samples</li>
<li><code>Query</code>: unlabeled sample that should be classified</li>
</ul>
<p>Output:</p>
<ul>
<li><code>Label</code>: the most fitting label for the query (any of the labels in the database)</li>
</ul>
<p>Steps:</p>
<ol>
<li>For all labeled samples in the database, calculate the distance between that sample and the query.</li>
<li>Find the database entry with the minimum distance to the query.</li>
<li>Output the label attached to this database entry.</li>
</ol>
<p>The basic idea remains the same with the main difference being that &quot;samples&quot; can be data shaped in any way and that labels can also vary freely.
The only difficulty may be how to properly define the &quot;distance&quot; between two samples, which is required to find the sample with minimal distance - the &quot;nearest neighbor&quot; that gives the algorithm its name.
To give a specific example, you could use this algorithm for speech recognition using small audio files of fixed length as samples and recognized words as labels.
As audio files are just a very long list of numbers that constitute a waveform, you could define the distance between two audio files to be the sum of the differences between these individual numbers.
Alternatively, you could also use a more involved definition like transforming both audio files into the frequency spectrum and comparing the dominant frequencies.
Like with audio files, you could use a nearest neighbor algorithm to recognize handwritten digits by using image files as samples and the digit that is seen in the image as label.
Here, a simple distance function might sum up the differences per pixel like we did for the audio files.</p>
<p>Going back to our spam filter example, we would use the following mapping:</p>
<table>
<thead>
<tr>
<th>General term</th>
<th>Specific term</th>
</tr>
</thead>
<tbody>
<tr>
<td>sample</td>
<td>email text</td>
</tr>
<tr>
<td>label</td>
<td>&quot;spam&quot; or &quot;ham&quot;</td>
</tr>
<tr>
<td>distance</td>
<td>number of matching words times -1</td>
</tr>
</tbody>
</table>
<p>Here you see a common adjustment that is often made in nearest neighbor algorithms:
For our emails, it is easier to define a measure for &quot;similarity&quot; than for &quot;distance&quot;.
In such cases, we need a trick that turns small similarities into large distances and large similarities into small distances.
The multiplication with -1 does just that.</p>
<p>As a last remark before we move on, I have called this algorithm a &quot;classifier&quot;, without defining the term.
A classifier is nothing more than an algorithm, which assigns labels to unlabeled data.
Most AI problems are classification problems, as &quot;intelligent&quot; choices often just require to recognize instances of a class of items like recognizing spoken words, or recognizing that an image shows a dog rather than a cat.</p>
<h2 id="going-into-detail">Going into detail</h2>
<p>Let's have a more detailed look at the distance within the nearest neighbor algorithm.
You probably have already noticed that this is where the magic happens. 🔮
Each nearest neighbor algorithm needs a sub-algorithm that defines the distance between two samples.
Only when we choose a good distance algorithm can we expect &quot;intelligent&quot; choices from the nearest neighbor classifier.</p>
<p>Luckily, there is a pretty generic distance algorithm that works for all samples that are &quot;just a bunch of numbers&quot;, which, as we have seen, is true for a surprisingly large variety of data types such as images and audio files.
This distance algorithm is called the <em>euclidean distance</em>, because it is based on euclidean geometry.
This is the same kind of math that you use to calculate the distance between two points in two or three dimensions - only that we are not in two- or three-dimensional, but in n-dimensional space.
If this sounds overly technical that is because it is.
n-dimensional space sounds cool, but in essence the algorithm is not much more complicated than our idea of taking individual differences and summing them up.
In fact, we do just that, but we take the square of the differences before we do the summing.
Before you get too many flashbacks to your last math lesson, let's just do a quick example:</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable rowspacing="0.24999999999999992em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>a</mi><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo separator="true">,</mo><mn>2</mn><mo separator="true">,</mo><mn>3</mn><mo separator="true">,</mo><mn>3</mn><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>b</mi><mo>=</mo><mo stretchy="false">(</mo><mn>5</mn><mo separator="true">,</mo><mn>2</mn><mo separator="true">,</mo><mn>4</mn><mo separator="true">,</mo><mn>5</mn><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
a = (1, 2, 3, 3)\\
b = (5, 2, 4, 5)
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.0000000000000004em;vertical-align:-1.2500000000000002em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7500000000000002em;"><span style="top:-3.91em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">3</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">3</span><span class="mclose">)</span></span></span><span style="top:-2.41em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mopen">(</span><span class="mord">5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">4</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">5</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2500000000000002em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>e</mi><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mn>5</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>2</mn><mo>−</mo><mn>2</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>3</mn><mo>−</mo><mn>4</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>3</mn><mo>−</mo><mn>5</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>16</mn><mo>+</mo><mn>0</mn><mo>+</mo><mn>1</mn><mo>+</mo><mn>4</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>21</mn></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
edist(a, b) &amp; = (1-5)^2 + (2-2)^2 + (3-4)^2 + (3-5)^2 \\
            &amp; = 16 + 0 + 1 + 4\\
            &amp; = 21
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.524108em;vertical-align:-2.012054em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.512054em;"><span style="top:-4.647946em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="mord mathdefault">d</span><span class="mord mathdefault">i</span><span class="mord mathdefault">s</span><span class="mord mathdefault">t</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">b</span><span class="mclose">)</span></span></span><span style="top:-3.147946em;"><span class="pstrut" style="height:3em;"></span><span class="mord"></span></span><span style="top:-1.6479460000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.012054em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.512054em;"><span style="top:-4.647946em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">5</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">2</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">4</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">5</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.147946em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">1</span><span class="mord">6</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">4</span></span></span><span style="top:-1.6479460000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">2</span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.012054em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>Here you have a sample <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">a</span></span></span></span> and a sample <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">b</span></span></span></span>, which are both a list of four numbers.
The function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">edist</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">e</span><span class="mord mathdefault">d</span><span class="mord mathdefault">i</span><span class="mord mathdefault">s</span><span class="mord mathdefault">t</span></span></span></span> calculates the euclidean distance by taking the difference between the first element of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">a</span></span></span></span> and the first element of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">b</span></span></span></span>, squaring the result, and then adding similar terms for the second, third, and fourth elements of both lists.</p>
<p>To get the <em>real</em> euclidean distance, you would have to take the square root of the final result, but since this does not change the ordering of how near a sample is to the query, we can just omit that.
AI math is chill like that. ❄️</p>
<p>This example would work quite the same way if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">a</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">b</span></span></span></span> were image files.
You would just have to list the color values (usually numbers between 0 and 255) of each pixel starting with the red channel of the pixel in the upper left of the image, followed by its green channel value, its blue channel value, then the three channels of the pixel to the right, and so on, until you reach the right edge of the image and start again at the second row of pixels below the first.
Et voilà, your pretty picture of your dog is now just a very long list of ugly numbers, and you can determine the euclidean distance between that picture of your dog and your friend's picture of their cat.</p>
<p>Another example where the euclidean distance can be applied is our spam detection algorithm.
It may not seem obvious, but there is also a way to turn text documents into just a bunch of numbers.
Actually, this approach is the basis for any kind of indexing used by your operating system or search engines like google to quickly search through enormous amounts of documents.
To do this, we need to restrict ourselves to a fixed number of words.
In practice, it would be sensible to use the 1000 or maybe 10.000 most common english words, but for the sake of this example let's just choose the three words &quot;prince&quot;, &quot;nigeria&quot; and &quot;harry&quot;.
An email is then just represented by three numbers p, n, and h, where p is one if &quot;prince&quot; occurs in the email and zero otherwise, while n is one if &quot;nigeria&quot; is present in the email and zero otherwise, and for h it is the same with the word &quot;harry&quot;.
Using this transformation, the emails in the previous post would become the following:</p>
<pre><code><code><div>[Database entry 1:]

Label: spam
Data: [1, 1, 0]


[Database entry 2:]

Label: ham
Data: [1, 1, 1]


[New email:]

Label: ???
Data: [1, 1, 1]
</div></code></code></pre>
<p>All the gossip is gone, but our classification still works:</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>e</mi><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy="false">(</mo><mi>e</mi><mi>n</mi><mi>t</mi><mi>r</mi><mi>y</mi><mn>1</mn><mo separator="true">,</mo><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mn>1</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mn>1</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>0</mn><mo>−</mo><mn>1</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>0</mn><mo>+</mo><mn>0</mn><mo>+</mo><mn>1</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>1</mn></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
edist(entry1, query) &amp; = (1-1)^2 + (1-1)^2 + (0-1)^2\\
                     &amp; = 0 + 0 + 1\\
                     &amp; = 1
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.524108em;vertical-align:-2.012054em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.512054em;"><span style="top:-4.647946em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="mord mathdefault">d</span><span class="mord mathdefault">i</span><span class="mord mathdefault">s</span><span class="mord mathdefault">t</span><span class="mopen">(</span><span class="mord mathdefault">e</span><span class="mord mathdefault">n</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="mord mathdefault">u</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span><span style="top:-3.147946em;"><span class="pstrut" style="height:3em;"></span><span class="mord"></span></span><span style="top:-1.6479460000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.012054em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.512054em;"><span style="top:-4.647946em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.147946em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span></span></span><span style="top:-1.6479460000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.012054em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>e</mi><mi>d</mi><mi>i</mi><mi>t</mi><mi>s</mi><mo stretchy="false">(</mo><mi>e</mi><mi>n</mi><mi>t</mi><mi>r</mi><mi>y</mi><mn>2</mn><mo separator="true">,</mo><mi>q</mi><mi>u</mi><mi>e</mi><mi>r</mi><mi>y</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mn>1</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mn>1</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mn>1</mn><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>0</mn><mo>+</mo><mn>0</mn><mo>+</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
edits(entry2, query) &amp; = (1-1)^2 + (1-1)^2 + (1-1)^2\\
                     &amp; = 0 + 0 + 0\\
                     &amp; = 0
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:4.524108em;vertical-align:-2.012054em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.512054em;"><span style="top:-4.647946em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">e</span><span class="mord mathdefault">d</span><span class="mord mathdefault">i</span><span class="mord mathdefault">t</span><span class="mord mathdefault">s</span><span class="mopen">(</span><span class="mord mathdefault">e</span><span class="mord mathdefault">n</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">q</span><span class="mord mathdefault">u</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span><span style="top:-3.147946em;"><span class="pstrut" style="height:3em;"></span><span class="mord"></span></span><span style="top:-1.6479460000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.012054em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.512054em;"><span style="top:-4.647946em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">1</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.147946em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">0</span></span></span><span style="top:-1.6479460000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.012054em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>Entry 2 has the minimum euclidean distance, and therefore we decide to correctly label the email of our friend from Nigeria about the Guarian Nigeraia as &quot;ham&quot;.
Only this time, our savior is not <code>&quot;harry&quot;</code>, but the last <code>1</code> in the query data (which of course is just <code>&quot;harry&quot;</code> in disguise 😉).</p>
<p>This representation of text as numbers already hints at a more sophisticated version of our spam detector:
Instead of just using the index list to store whether a word is present (1) or not (0), we could also store the <em>count</em> how often the word was found, which would enable us to distinguish between frequent words, which are probably important for the message content, and infrequent words, which might only be anecdotal references.
To not put undue emphasis on common but &quot;uninteresting&quot; words like &quot;a&quot; or &quot;the&quot;, we would then ignore these words and do not use them to build our index lists.
As already mentioned, most if not all search engines perform this kind of indexing and distance calculation.
In fact, we could turn our nearest neighbor spam detection algorithm into a search engine, by using a short search string as query instead of a full email and outputting the email text itself instead of its label.</p>
<h2 id="from-1-to-k">From 1 to k</h2>
<p>Now that you know all about euclidean distances in  n-dimensional space and can shine with your knowledge at any dinner table, the only step that remains is to make the step from 1 to k neighbors:</p>
<h3 id="algorithm-k-nearest-neighbors-classifier">Algorithm: K-nearest neighbors classifier</h3>
<p>Inputs:</p>
<ul>
<li><code>Database</code>: list of labeled samples</li>
<li><code>Query</code>: unlabeled sample that should be classified</li>
</ul>
<p>Output:</p>
<ul>
<li><code>Label</code>: the most fitting label for the query (any of the labels in the database)</li>
</ul>
<p>Steps:</p>
<ol>
<li>For all labeled samples in the database, calculate the distance between that sample and the query.</li>
<li>Find the k database entries with the least distance to the query.</li>
<li>Count how often each possible label occurs within these k nearest neighbors.</li>
<li>Output the label with the highest voting count.</li>
</ol>
<p>The main change is that we now not only keep one nearest neighbor, but the k nearest neighbors.
As it is often with neighbors, they do not have to agree on a single decision.
We now can have k conflicting labels from which we have to choose one.
This is done by a so-called <em>majority voting</em>, in which each neighbor casts a vote for their label, and we then select the label that received the most votes.
Of course, we have to break ties somehow, but these details are not important for the general idea of the algorithm.</p>
<p>The beauty of this variant of the nearest neighbors algorithm is that it protects us against bad apples in our data.
Since the labels stem from human decisions, they are subject to human error.
But even without errors there may be instances of &quot;exceptional&quot; samples - for example, a &quot;ham&quot; email that is surrounded by very similar &quot;spam&quot; emails.
An example could be a system administrator that receives a forwarded spam email of an employee who wants to know whether the spam email contains malicious code.
The email itself is not spam, but it <em>contains</em> a full spam email in verbatim.
What is the &quot;correct&quot; label in this case?</p>
<p>Real world problems are full of these examples and therefore the k-nearest neighbor algorithm offers some welcome robustness.
If the sysadmin mail sits in the database with the &quot;ham&quot; label, and our AI is asked to classify a new spam email that is very similar to the forwarded spam, it may find that its nearest neighbor is the sysadmin mail and falsely output the &quot;ham&quot; label.
A 5-nearest neighbor classifier would instead see that while there is one very close example of &quot;ham&quot;, there are also four examples of &quot;spam&quot; that are only a little more distant.
Through majority voting, it would correctly label the newly received spam email as &quot;spam&quot;.</p>
<h2 id="remarks-about-real-world-application">Remarks about real-world application</h2>
<p>I have already hinted at the fact that the k-nearest neighbor (k-NN) algorithm is part of every AI researchers toolkit.
That is mainly, because it is extremely simple to write up a k-NN algorithm for almost any problem and therefore get a first glimpse at what can be achieved with a given dataset.
If a k-NN classifier performs reasonably well, there is hope that a more sophisticated algorithm will perform even better.
If, however, it does not pick up any usable pattern, there may be a problem with the data itself.</p>
<p>Apart from a quick diagnostic tool, a k-NN classifier can also simply be &quot;good enough&quot; for a problem.
With a clever implementation there are surprisinly many instances where choosing a more sophisticated classifier yields little to no improvement.
However, such a &quot;clever&quot; implementation has to iron out several issues in our current definition that have to do with large databases:</p>
<ul>
<li>Since we only need to keep the k minimal distances in mind, there is no need to actually <em>store</em> the calculated distances for each sample in the database.</li>
<li>In the majority voting, we also do not have to store counts for every possible lables, but just for the labels that have at least one vote.</li>
<li>The major downside of the k-NN algorithm is that is becomes slow with large databases, because calculating the distance to millions of entries is time-consuming.
This can be counteracted by a smarter way of organizing the database.
Instead of just a list of samples, it can be structured for easier access, much like a telephone book or a map. If you search for a restaurant in London, you do not have to start from the arctic, circling your way around the globe towards the antarctic, but you can use the nature of your query to quickly narrow down the search space. Similarly, you would not start at the front of a telephone book when you search for a &quot;Zacharias Ziegler&quot; or a &quot;Madison Meriwether&quot;, but you could narrow down the possible pages because you have an intuition about how human names are distributed along the alphabet.
For data that is a large list of numbers, there is a standard solution that is called a <a href="https://en.wikipedia.org/wiki/K-d_tree">k-d tree</a>.
Although it is quite involved and most certainly beyond the scope of this article, I have to drop a link here, because it is such a game changer for the speed achievable with a k-NN algorithm.</li>
</ul>
<!--
NOTE: Maybe this should be an ipython notebook?
  - or each post should be accompanied by one?

Examples (should be applications of AI that everyone is familiar with)

- Spam filter (0 = no spam, 1 = spam)
  - transformation of email to (relative) word counts
    - easier first step: just set of words (there/not there)
    - even easier: just select 5 words, which seem important
  - "distance" = percentage of words occurring in both e-mails
- Netflix recommendations (0 = won't like, 1 = will like)


Topics (each could be one post):

- 1-NN
- k-NN
- Data: More is better
  - show performance gain with increasing amount of data
  - feature vector grows by one bit => percentage of feature space covered by samples is halved
  - => massive amounts of data required for complex problems
- Performance metrics
  - accuracy
  - precition/recall
  - sensitivity/specificity
  - f-measure
  - confusion matrix
- The problem of Generalization vs Overfitting
  - separate knowledge base into test and train set
  - only result on unseen data is interesting
  - what is truly unseen? (unseen date?, unseen sender?, ...)
  - think about variance to be expected in real world vs variance in training set
- Bias (never trust your data)
  - uneven distribution of samples per class
  - what if we filter out E-mails from dyslexics or foreign speakers?
  - who decides what is spam? (Ground truth)
- local vs global optimum: k as (hyper)-parameter
  - increase by one until result becomes worse again
- unsupervised learning with kMeans
  - From kNN to jMeans: just slap j random vectors with class 1 to j in the kNN
- ANNs for dummies
- similarities between ANNs and kNN
  - both are classifiers (input vector -> class)
  - both rely on data
- differences between ANNs and kNN
  - number of parameters/features
  - black box
  - training effort / required hardware
-->
    </body>
    </html>